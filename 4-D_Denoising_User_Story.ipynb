{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon 9/5/2024\n",
    "- 4-D Denoising User Story in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will be using the poetry run denoise command \n",
    "- Follow the set up steps in the github repository in order to get the poetry command working.   \n",
    "https://github.com/NIA-IRP/NIA_Hackathon_2024/tree/main/TEAM_06\n",
    "\n",
    "- This is where I got my dataset: https://openneuro.org/datasets/ds001420/versions/1.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIFTI file viewer\n",
    "Program to see nifti files\n",
    "MIPAV   \n",
    "Ask NIH IT to download this on your laptop  \n",
    "https://mipav.cit.nih.gov   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "from nibabel.filename_parser import splitext_addext\n",
    "from nibabel.loadsave import load as nib_load\n",
    "from nibabel.spatialimages import SpatialImage\n",
    "\n",
    "from dynamicpet.denoise import hypr\n",
    "from dynamicpet.denoise import nesma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to install datalad and git-annex using conda install so you can work with the dataset from openneuro\n",
    "# git-annex only works on linux enviornments \n",
    "# you can also manually download the files themselves if git-annex isn't working\n",
    "#### make sure to grab both the .nii and the .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code to run:\n",
    "# $ poetry run denoise PET --model SRTMZhou2003 --refmask <REFMASK> --outputdir <OUTPUTDIR> --fwhm 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3941335125.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    poetry run denoise PET --outputdir /Users/uriartelopezjr/Documents/hackathon/dynamicpet/denoise_output\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# This doesn't work because I need to add the symbolic link packages as mentioned above. \n",
    "# For now I'm going to try and manually download them, add them to a folder, and then reference it\n",
    "# poetry run denoise --method HYPRLR --outputdir /Users/uriartelopezjr/Documents/hackathon/dynamicpet/denoise_output /Users/uriartelopezjr/Documents/hackathon/ds001420/sub-01/ses-baseline/pet/sub-01_ses-baseline_pet.nii.gz\n",
    "\n",
    "\n",
    "# 9/5/2024 3pm version\n",
    "### you can change the value next to --fwhm (in mm) \n",
    "# https://dynamicpet.readthedocs.io/en/latest/usage.html\n",
    "poetry run denoise --method HYPRLR --fwhm 5 --outputdir /Users/uriartelopezjr/Documents/hackathon/dynamicpet/denoise_output /Users/uriartelopezjr/Documents/hackathon/open_neuro_data/sub-01_ses-baseline_pet.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamicpet-9lkmTgRy-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
